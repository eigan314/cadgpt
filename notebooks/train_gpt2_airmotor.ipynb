{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cFxD8v3YtjD",
        "outputId": "46e6e6db-ccf2-4367-d79d-aec3407f6206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo ready: polaris314/cadgpt-gpt2-train (private)\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face login and private repo setup\n",
        "import os\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfApi, login, create_repo\n",
        "\n",
        "# Read token from env or fallback file\n",
        "HF_TOKEN = os.getenv('HF_TOKEN')\n",
        "if not HF_TOKEN:\n",
        "    token_file = Path('/home/ubuntu/cad-llm/notebooks/hf_token.txt')\n",
        "    if token_file.exists():\n",
        "        HF_TOKEN = token_file.read_text().strip()\n",
        "\n",
        "assert HF_TOKEN, 'HF_TOKEN not set. Set env or create notebooks/hf_token.txt'\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "api = HfApi()\n",
        "user = api.whoami(token=HF_TOKEN).get('name') or api.whoami(token=HF_TOKEN).get('orgs', [{}])[0].get('name')\n",
        "HF_REPO = os.getenv('HF_REPO', f'{user}/cadgpt-gpt2-train')\n",
        "create_repo(HF_REPO, private=True, exist_ok=True, token=HF_TOKEN)\n",
        "print(f'Repo ready: {HF_REPO} (private)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defined make_args_with_hub(). After creating training_args, run:\n",
            "    training_args = make_args_with_hub(training_args)\n"
          ]
        }
      ],
      "source": [
        "# Configure Trainer to push all checkpoints to the private repo\n",
        "# Assumes you define `training_args = TrainingArguments(...)` later\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "assert 'HF_REPO' in globals(), 'Run the HF login/setup cell first.'\n",
        "\n",
        "PUSH_EVERY_STEPS = int(os.getenv('PUSH_EVERY_STEPS', '200'))  # align with save_steps\n",
        "\n",
        "def make_args_with_hub(base: TrainingArguments) -> TrainingArguments:\n",
        "    base.push_to_hub = True\n",
        "    base.hub_model_id = HF_REPO\n",
        "    base.hub_private_repo = True\n",
        "    base.hub_token = HF_TOKEN\n",
        "    base.save_strategy = 'steps'\n",
        "    base.save_steps = max(getattr(base, 'save_steps', 200) or 200, 50)\n",
        "    base.save_total_limit = 3  # Keep only last 3 checkpoints locally\n",
        "    base.load_best_model_at_end = True  # Load best model for final push\n",
        "    base.push_to_hub_model_id = HF_REPO\n",
        "    base.hub_always_push = False  # Only push final model, not every checkpoint\n",
        "    base.logging_steps = min(getattr(base, 'logging_steps', 50) or 50, base.save_steps)\n",
        "    return base\n",
        "\n",
        "def upload_checkpoint_to_hub(checkpoint_path, step_num):\n",
        "    \"\"\"Upload a specific checkpoint to HF Hub with unique naming\"\"\"\n",
        "    from huggingface_hub import HfApi\n",
        "    import shutil\n",
        "    import tempfile\n",
        "    \n",
        "    api = HfApi(token=HF_TOKEN)\n",
        "    \n",
        "    # Create a temporary directory for the checkpoint\n",
        "    with tempfile.TemporaryDirectory() as temp_dir:\n",
        "        # Copy checkpoint files to temp directory\n",
        "        checkpoint_name = f\"checkpoint-{step_num}\"\n",
        "        temp_checkpoint_path = os.path.join(temp_dir, checkpoint_name)\n",
        "        shutil.copytree(checkpoint_path, temp_checkpoint_path)\n",
        "        \n",
        "        # Upload to HF Hub with unique name\n",
        "        repo_id = f\"{HF_REPO}-checkpoint-{step_num}\"\n",
        "        api.create_repo(repo_id, private=True, exist_ok=True, token=HF_TOKEN)\n",
        "        api.upload_folder(\n",
        "            folder_path=temp_checkpoint_path,\n",
        "            repo_id=repo_id,\n",
        "            token=HF_TOKEN\n",
        "        )\n",
        "        print(f\"✅ Uploaded checkpoint-{step_num} to {repo_id}\")\n",
        "\n",
        "print('Defined make_args_with_hub() and upload_checkpoint_to_hub().')\n",
        "print('After creating training_args, run:')\n",
        "print('    training_args = make_args_with_hub(training_args)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYmoOnBNpQDI",
        "outputId": "d4618e72-79c6-44c3-e888-db1814f0a33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Sep  5 11:18:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 570.148.08             Driver Version: 570.148.08     CUDA Version: 12.8     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Quadro RTX 6000                On  |   00000000:07:00.0 Off |                  Off |\n",
            "| 33%   31C    P8             15W /  260W |       4MiB /  24576MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWNmtcoKuFrY"
      },
      "source": [
        "# **air motor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kFf_P82t7m-"
      },
      "source": [
        "# **generate dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYvUo6PUpP_B",
        "outputId": "fa50fe63-95fe-48f4-aa6f-f7e67273bcf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved /home/ubuntu/cad-llm/notebooks/air_motor_prompts.csv and /home/ubuntu/cad-llm/notebooks/air_motor_prompts.jsonl with 30000 samples (3 per input row).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd, json\n",
        "\n",
        "# Path to your uploaded Excel in Colab\n",
        "in_path = \"/home/ubuntu/cad-llm/datasets/air_motor.xlsx\"\n",
        "out_stem = \"/home/ubuntu/cad-llm/notebooks/air_motor_prompts\"\n",
        "\n",
        "# --- required columns ---\n",
        "REQUIRED_COLS = [\n",
        "    \"pressure_bar\",\"pressure_mpa\",\"stroke_length\",\n",
        "    \"cyl_id\",\"cyl_len\",\"cyl_thk\",\"cyl_od\",\n",
        "    \"disc_dia\",\"disc_thk\",\"thru_hole\",\"counterbore\",\"groove_dia\",\"groove_height\",\n",
        "    \"head_dia\",\"head_length\",\"neck_dia\",\"neck_length\",\"chamf_dist\",\n",
        "    \"piston_dia\",\"piston_length\",\"ext_length_A\",\"ext_dia_A\",\"threaded_depth\",\n",
        "    \"flange_dia\",\"flange_thk\",\"hub_od\",\"hub_id\",\"hub_length\",\n",
        "    \"ext_dia_B\",\"ext_length_B\",\"center_hole_dia\",\"center_hole_depth\",\n",
        "    \"bolt_hole_radius\",\"pattern_radius\",\"small_radius\",\"n_bolts\",\n",
        "]\n",
        "\n",
        "# --- load file ---\n",
        "df = pd.read_excel(in_path)\n",
        "\n",
        "missing = [c for c in REQUIRED_COLS if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "# --- prompt template ---\n",
        "import random\n",
        "\n",
        "PROMPT_TEMPLATES = {\n",
        "    \"piston_disc\": [\n",
        "        \"Generate a piston disc for an air motor with cylinder ID {cyl_id}mm, stroke length {stroke_length}mm, designed for pressure {pressure_bar} bar.\",\n",
        "        \"Design a piston disc for a cylinder of ID {cyl_id} mm and stroke {stroke_length} mm, operating at {pressure_bar} bar.\",\n",
        "        \"Create a piston disc model for an air motor (cyl ID {cyl_id} mm, stroke {stroke_length} mm, pressure {pressure_bar} bar).\",\n",
        "        \"Build the piston disc of an air motor: bore {cyl_id} mm, stroke {stroke_length} mm, working pressure {pressure_bar} bar.\"\n",
        "    ],\n",
        "    \"piston_rod\": [\n",
        "        \"Generate a piston rod for an air motor with cylinder ID {cyl_id} mm, stroke {stroke_length} mm, and pressure {pressure_bar} bar.\",\n",
        "        \"Design a piston rod for a cylinder (bore {cyl_id} mm, stroke {stroke_length} mm, pressure {pressure_bar} bar).\",\n",
        "        \"Create a piston rod model: cyl ID {cyl_id} mm, stroke length {stroke_length} mm, pressure {pressure_bar} bar.\",\n",
        "        \"Build the piston rod for an air motor bore {cyl_id} mm, stroke {stroke_length} mm, at {pressure_bar} bar.\"\n",
        "    ],\n",
        "    \"flange\": [\n",
        "        \"Generate a flange for an air motor with cylinder ID {cyl_id} mm, stroke {stroke_length} mm, and pressure {pressure_bar} bar.\",\n",
        "        \"Design a mounting flange for a cylinder (ID {cyl_id} mm, stroke {stroke_length} mm, pressure {pressure_bar} bar).\",\n",
        "        \"Create a flange for an air motor: bore {cyl_id} mm, stroke {stroke_length} mm, working pressure {pressure_bar} bar.\",\n",
        "        \"Build a flange component for cylinder ID {cyl_id} mm, stroke {stroke_length} mm, operating at {pressure_bar} bar.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "def prompt_for(part: str, row: pd.Series) -> str:\n",
        "    tpl = random.choice(PROMPT_TEMPLATES[part])\n",
        "    return tpl.format(\n",
        "        cyl_id=int(round(float(row[\"cyl_id\"]))),\n",
        "        stroke_length=int(round(float(row[\"stroke_length\"]))),\n",
        "        pressure_bar=float(row[\"pressure_bar\"])\n",
        "    )\n",
        "\n",
        "\n",
        "# --- cadquery code templates ---\n",
        "CQ_TEMPLATES = {\n",
        "    \"piston_disc\": r\"\"\"\n",
        "# piston disc\n",
        "cbore_height = 3\n",
        "piston_disc = (cq.Workplane(\"XY\").circle(disc_dia/2).extrude(disc_thk))\n",
        "piston_disc = (piston_disc.faces(\">Z\").workplane()\n",
        "               .cboreHole(thru_hole, counterbore, cbore_height, depth=None))\n",
        "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -(disc_thk - groove_height)/2)\n",
        "               .circle(groove_dia/2).circle(disc_dia/2).cutBlind(-groove_height))\n",
        "\"\"\",\n",
        "    \"piston_rod\": r\"\"\"\n",
        "# piston rod\n",
        "head = (cq.Workplane(\"XY\").circle(head_dia/2).extrude(head_length).edges(\"<Z\").chamfer(2.5))\n",
        "neck = (head.faces(\">Z\").circle(neck_dia/2).extrude(neck_length))\n",
        "shoulder = (neck.faces(\">Z\").circle((neck_dia + 5)/2)\n",
        "            .workplane(offset=chamf_dist).circle(piston_dia/2).loft(combine=\"a\"))\n",
        "piston = (shoulder.faces(\">Z\").circle(piston_dia/2).extrude(piston_length))\n",
        "piston = (piston.faces(\">Z\").workplane().circle(ext_dia_A/2).extrude(ext_length_A).fillet(0.5))\n",
        "\"\"\",\n",
        "    \"flange\": r\"\"\"\n",
        "# flange\n",
        "flange = (cq.Workplane(\"XY\").circle(flange_dia/2).extrude(flange_thk).edges(\">Z\").fillet(1))\n",
        "flange = (flange.faces(\">Z\").workplane(centerOption=\"CenterOfMass\")\n",
        "          .polarArray(pattern_radius, 0, 360, int(n_bolts))\n",
        "          .circle(small_radius).circle(bolt_hole_radius)\n",
        "          .extrude(-flange_thk).edges(\"|Z\").fillet(5))\n",
        "flange = (flange.faces(\">Z\").workplane().hole(center_hole_dia, center_hole_depth))\n",
        "flange_hub = (flange.faces(\">Z\").workplane().center(0,0)\n",
        "              .circle(hub_od/2).circle(hub_id/2).extrude(hub_length))\n",
        "flange = (flange_hub.faces(\">Z\").workplane()\n",
        "          .circle(ext_dia_B/2).circle(hub_id/2).extrude(ext_length_B))\n",
        "\n",
        "\"\"\",\n",
        "}\n",
        "\n",
        "def code_for(part, row):\n",
        "    header_lines = [\"import cadquery as cq\", \"\", \"# Parameters from dataset row\"]\n",
        "    for k, v in row.items():\n",
        "        if pd.isna(v): continue\n",
        "        try:\n",
        "            fv = float(v)\n",
        "            header_lines.append(f\"{k} = {int(round(fv))}\" if abs(fv-round(fv)) < 1e-9 else f\"{k} = {fv}\")\n",
        "        except Exception:\n",
        "            header_lines.append(f\"{k} = {repr(v)}\")\n",
        "    return \"\\n\".join(header_lines) + \"\\n\" + CQ_TEMPLATES[part]\n",
        "\n",
        "# --- generate dataset ---\n",
        "rows_out = []\n",
        "for idx, row in df.iterrows():\n",
        "    for part in [\"piston_disc\",\"piston_rod\",\"flange\"]:\n",
        "        rows_out.append({\n",
        "            \"row_id\": int(idx),\n",
        "            \"part\": part,\n",
        "            \"prompt\": prompt_for(part,row),\n",
        "            \"completion\": code_for(part,row),\n",
        "        })\n",
        "\n",
        "out_csv   = out_stem + \".csv\"\n",
        "out_jsonl = out_stem + \".jsonl\"\n",
        "\n",
        "pd.DataFrame(rows_out).to_csv(out_csv, index=False)\n",
        "with open(out_jsonl,\"w\",encoding=\"utf-8\") as f:\n",
        "    for rec in rows_out:\n",
        "        f.write(json.dumps(rec, ensure_ascii=False)+\"\\n\")\n",
        "\n",
        "print(f\"✅ Saved {out_csv} and {out_jsonl} with {len(rows_out)} samples \"\n",
        "      f\"(3 per input row).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4A9SUt8MIMy"
      },
      "source": [
        "# **train gpt2 on generated data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Hugging Face token loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Read Hugging Face Token from local file\n",
        "try:\n",
        "    with open('hf_token.txt', 'r') as f:\n",
        "        HF_TOKEN = f.read().strip()\n",
        "    print(\"✅ Hugging Face token loaded successfully\")\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ hf_token.txt file not found. Please create it with your HF token.\")\n",
        "    HF_TOKEN = None\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error reading token file: {e}\")\n",
        "    HF_TOKEN = None\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    print(\"⚠️ Warning: Hugging Face token not available. Some operations may fail.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 600/600 [00:00<00:00, 1937.06 examples/s]\n",
            "/tmp/ipykernel_16922/2436310189.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7350' max='7350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7350/7350 1:02:45, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.298700</td>\n",
              "      <td>0.181584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.123600</td>\n",
              "      <td>0.099739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.087600</td>\n",
              "      <td>0.069223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.070300</td>\n",
              "      <td>0.055413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.060100</td>\n",
              "      <td>0.053136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.055300</td>\n",
              "      <td>0.045289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.051400</td>\n",
              "      <td>0.042706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.047300</td>\n",
              "      <td>0.040301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.046300</td>\n",
              "      <td>0.040413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.046100</td>\n",
              "      <td>0.038608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.042800</td>\n",
              "      <td>0.037571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.042800</td>\n",
              "      <td>0.036736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.039500</td>\n",
              "      <td>0.035297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.035083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.038800</td>\n",
              "      <td>0.034660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.034984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>0.035908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.034322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>0.032796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.037200</td>\n",
              "      <td>0.033099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.036300</td>\n",
              "      <td>0.032424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>0.033445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.034700</td>\n",
              "      <td>0.031659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>0.031472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.034400</td>\n",
              "      <td>0.031369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.033700</td>\n",
              "      <td>0.030900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.033800</td>\n",
              "      <td>0.030996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.033400</td>\n",
              "      <td>0.030806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.034100</td>\n",
              "      <td>0.030648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.033000</td>\n",
              "      <td>0.031890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.030373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.032200</td>\n",
              "      <td>0.030219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.032900</td>\n",
              "      <td>0.030095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.033600</td>\n",
              "      <td>0.029952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.032800</td>\n",
              "      <td>0.029975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.029828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :   3%|▎         | 16.8MB /  498MB,   ???B/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  12%|█▏        | 58.7MB /  498MB,  209MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  20%|██        |  101MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  29%|██▊       |  143MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  37%|███▋      |  184MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  45%|████▌     |  226MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  54%|█████▍    |  268MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  62%|██████▏   |  310MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  69%|██████▉   |  344MB /  498MB,  204MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  79%|███████▉  |  394MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  86%|████████▌ |  428MB /  498MB,  205MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  94%|█████████▍|  470MB /  498MB,  206MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (2 / 2)                : 100%|██████████|  498MB /  498MB,  200MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "Processing Files (2 / 2)                : 100%|██████████|  498MB /  498MB,  185MB/s  \n",
            "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...books/checkpoints/training_args.bin: 100%|██████████| 5.78kB / 5.78kB            \n",
            "  ...books/checkpoints/model.safetensors: 100%|██████████|  498MB /  498MB            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved finetuned model to /home/ubuntu/cad-llm/cad_llm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "# CONFIG\n",
        "DATA_JSON = \"/home/ubuntu/cad-llm/notebooks/air_motor_prompts.jsonl\"  # adjust path if needed\n",
        "BASE_MODEL = \"gpt2\"\n",
        "OUT_DIR = \"/home/ubuntu/cad-llm/cad_llm\"\n",
        "EPOCHS = 2              # start with 2, bump to 3 if eval loss still dropping\n",
        "BATCH = 2               # per-device batch\n",
        "GRAD_ACCUM = 4          # effective batch = BATCH * GRAD_ACCUM\n",
        "MAX_LENGTH = 1024       # GPT-2 context size\n",
        "LR = 5e-5\n",
        "SEED = 42\n",
        "\n",
        "\n",
        "def make_text(example):\n",
        "    sep = \"\\n### CADQUERY CODE\\n\"\n",
        "    prompt = (example.get(\"prompt\") or \"\").strip()\n",
        "    code = (example.get(\"completion\") or \"\").strip()  # <-- FIXED\n",
        "    return {\"text\": prompt + sep + code + \"\\n\"}\n",
        "\n",
        "def main():\n",
        "    # load json dataset\n",
        "    raw_ds = load_dataset(\"json\", data_files=DATA_JSON, split=\"train\")\n",
        "    # tiny eval split (2%)\n",
        "    splits = raw_ds.train_test_split(test_size=0.02, seed=SEED)\n",
        "    train_ds, eval_ds = splits[\"train\"], splits[\"test\"]\n",
        "\n",
        "    # combine fields -> training text\n",
        "    train_ds = train_ds.map(make_text, remove_columns=train_ds.column_names)\n",
        "    eval_ds  = eval_ds.map(make_text, remove_columns=eval_ds.column_names)\n",
        "\n",
        "    # Pass the token explicitly when loading tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True, token=HF_TOKEN)\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.add_special_tokens({\"pad_token\": tokenizer.eos_token})\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, token=HF_TOKEN)\n",
        "    model.resize_token_embeddings(len(tokenizer))  # <-- align with tokenizer\n",
        "\n",
        "    def tokenize_fn(batch):\n",
        "        return tokenizer(\n",
        "            batch[\"text\"],\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH,\n",
        "            padding=\"max_length\",\n",
        "            return_attention_mask=True,\n",
        "        )\n",
        "\n",
        "    train_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "    eval_tok  = eval_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"checkpoints\",\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH,\n",
        "        gradient_accumulation_steps=GRAD_ACCUM,   # effective batch > 8k tokens/step\n",
        "        learning_rate=LR,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=50,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=200,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=200,\n",
        "        save_total_limit=None,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_loss\",\n",
        "        greater_is_better=False,\n",
        "        fp16=True,   # safe for Colab T4\n",
        "        report_to=\"none\",\n",
        "        seed=SEED,\n",
        "        # Pass the token to the Trainer arguments as well (optional but good practice)\n",
        "        hub_token=HF_TOKEN,\n",
        "    )\n",
        "    \n",
        "    training_args = make_args_with_hub(training_args)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_tok,\n",
        "        eval_dataset=eval_tok,\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model(OUT_DIR)\n",
        "    tokenizer.save_pretrained(OUT_DIR)\n",
        "    print(\"✅ Saved finetuned model to\", OUT_DIR)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Uploading to single repository: polaris314/cadgpt-gpt2-train\n",
            "🚀 Uploading final model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :   3%|▎         | 16.8MB /  498MB,   ???B/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  12%|█▏        | 58.7MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  20%|██        |  101MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  30%|███       |  151MB /  498MB,  224MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  37%|███▋      |  184MB /  498MB,  210MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  47%|████▋     |  235MB /  498MB,  218MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  56%|█████▌    |  277MB /  498MB,  217MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  67%|██████▋   |  335MB /  498MB,  228MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  74%|███████▍  |  369MB /  498MB,  220MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  83%|████████▎ |  411MB /  498MB,  219MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  91%|█████████ |  453MB /  498MB,  218MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (1 / 2)                :  99%|█████████▉|  495MB /  498MB,  217MB/s  \n",
            "\u001b[A\n",
            "\n",
            "Processing Files (2 / 2)                : 100%|██████████|  498MB /  498MB,  200MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "Processing Files (2 / 2)                : 100%|██████████|  498MB /  498MB,  185MB/s  \n",
            "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...s/cad-llm/cad_llm/training_args.bin: 100%|██████████| 5.78kB / 5.78kB            \n",
            "  ...s/cad-llm/cad_llm/model.safetensors: 100%|██████████|  498MB /  498MB            \n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Final model uploaded to polaris314/cadgpt-gpt2-train\n",
            "📦 Found 37 total checkpoints...\n",
            "🎯 Uploading 4 important checkpoints...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :   6%|▌         | 92.2MB / 1.49GB,   ???B/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  12%|█▏        |  176MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  17%|█▋        |  260MB / 1.49GB,  420MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  23%|██▎       |  344MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  29%|██▊       |  428MB / 1.49GB,  420MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  34%|███▍      |  512MB / 1.49GB,  420MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  39%|███▉      |  587MB / 1.49GB,  413MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  45%|████▍     |  671MB / 1.49GB,  414MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  51%|█████     |  755MB / 1.49GB,  414MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  56%|█████▌    |  839MB / 1.49GB,  415MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  62%|██████▏   |  931MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  66%|██████▋   |  993MB / 1.49GB,  409MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  70%|██████▉   | 1.04GB / 1.49GB,  396MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  73%|███████▎  | 1.08GB / 1.49GB,  382MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  75%|███████▌  | 1.13GB / 1.49GB,  369MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  78%|███████▊  | 1.17GB / 1.49GB,  359MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  81%|████████  | 1.21GB / 1.49GB,  350MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  84%|████████▍ | 1.25GB / 1.49GB,  341MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  86%|████████▌ | 1.29GB / 1.49GB,  332MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  89%|████████▉ | 1.33GB / 1.49GB,  325MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  93%|█████████▎| 1.39GB / 1.49GB,  324MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  96%|█████████▌| 1.43GB / 1.49GB,  318MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  98%|█████████▊| 1.46GB / 1.49GB,  311MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  305MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  280MB/s  \n",
            "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ckpoint-step-7350/training_args.bin: 100%|██████████| 5.78kB / 5.78kB            \n",
            "  .../checkpoint-step-7350/rng_state.pth: 100%|██████████| 14.6kB / 14.6kB            \n",
            "  ...lhjy/checkpoint-step-7350/scaler.pt: 100%|██████████| 1.38kB / 1.38kB            \n",
            "  ...y/checkpoint-step-7350/scheduler.pt: 100%|██████████| 1.47kB / 1.47kB            \n",
            "  ...ckpoint-step-7350/model.safetensors: 100%|██████████|  498MB /  498MB            \n",
            "  ...y/checkpoint-step-7350/optimizer.pt: 100%|██████████|  996MB /  996MB            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Checkpoint-7350 uploaded to polaris314/cadgpt-gpt2-train/checkpoints/checkpoint-step-7350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :   6%|▌         | 83.9MB / 1.49GB,   ???B/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  12%|█▏        |  185MB / 1.49GB,  503MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  17%|█▋        |  260MB / 1.49GB,  441MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  23%|██▎       |  344MB / 1.49GB,  434MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  29%|██▊       |  428MB / 1.49GB,  430MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  34%|███▍      |  512MB / 1.49GB,  428MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  40%|███▉      |  595MB / 1.49GB,  426MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  45%|████▌     |  679MB / 1.49GB,  425MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  51%|█████     |  763MB / 1.49GB,  425MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  57%|█████▋    |  847MB / 1.49GB,  424MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  62%|██████▏   |  931MB / 1.49GB,  424MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  67%|██████▋   | 1.00GB / 1.49GB,  417MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  70%|██████▉   | 1.04GB / 1.49GB,  400MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  73%|███████▎  | 1.08GB / 1.49GB,  385MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  75%|███████▌  | 1.13GB / 1.49GB,  373MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  79%|███████▉  | 1.18GB / 1.49GB,  364MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  82%|████████▏ | 1.22GB / 1.49GB,  355MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  84%|████████▍ | 1.26GB / 1.49GB,  346MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  87%|████████▋ | 1.30GB / 1.49GB,  339MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  90%|█████████ | 1.35GB / 1.49GB,  332MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  93%|█████████▎| 1.39GB / 1.49GB,  326MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  96%|█████████▌| 1.43GB / 1.49GB,  320MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  98%|█████████▊| 1.47GB / 1.49GB,  315MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  306MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  282MB/s  \n",
            "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ckpoint-step-7200/training_args.bin: 100%|██████████| 5.78kB / 5.78kB            \n",
            "  .../checkpoint-step-7200/rng_state.pth: 100%|██████████| 14.6kB / 14.6kB            \n",
            "  ...f68d/checkpoint-step-7200/scaler.pt: 100%|██████████| 1.38kB / 1.38kB            \n",
            "  ...d/checkpoint-step-7200/scheduler.pt: 100%|██████████| 1.47kB / 1.47kB            \n",
            "  ...ckpoint-step-7200/model.safetensors: 100%|██████████|  498MB /  498MB            \n",
            "  ...d/checkpoint-step-7200/optimizer.pt: 100%|██████████|  996MB /  996MB            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Checkpoint-7200 uploaded to polaris314/cadgpt-gpt2-train/checkpoints/checkpoint-step-7200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :   7%|▋         |  101MB / 1.49GB,   ???B/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  11%|█         |  168MB / 1.49GB,  336MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  17%|█▋        |  260MB / 1.49GB,  398MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  24%|██▎       |  352MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  30%|██▉       |  444MB / 1.49GB,  430MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  35%|███▍      |  520MB / 1.49GB,  420MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  41%|████      |  612MB / 1.49GB,  426MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  47%|████▋     |  696MB / 1.49GB,  426MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  52%|█████▏    |  780MB / 1.49GB,  425MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  58%|█████▊    |  872MB / 1.49GB,  429MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  64%|██████▍   |  956MB / 1.49GB,  428MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  68%|██████▊   | 1.02GB / 1.49GB,  417MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  71%|███████   | 1.06GB / 1.49GB,  400MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  73%|███████▎  | 1.09GB / 1.49GB,  382MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  76%|███████▌  | 1.14GB / 1.49GB,  369MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  79%|███████▉  | 1.18GB / 1.49GB,  359MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  82%|████████▏ | 1.22GB / 1.49GB,  350MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  84%|████████▍ | 1.26GB / 1.49GB,  341MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  87%|████████▋ | 1.30GB / 1.49GB,  334MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  91%|█████████ | 1.35GB / 1.49GB,  330MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  93%|█████████▎| 1.39GB / 1.49GB,  322MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  96%|█████████▌| 1.43GB / 1.49GB,  316MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  98%|█████████▊| 1.47GB / 1.49GB,  311MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  303MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  279MB/s  \n",
            "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ckpoint-step-7000/training_args.bin: 100%|██████████| 5.78kB / 5.78kB            \n",
            "  .../checkpoint-step-7000/rng_state.pth: 100%|██████████| 14.6kB / 14.6kB            \n",
            "  ...4syd/checkpoint-step-7000/scaler.pt: 100%|██████████| 1.38kB / 1.38kB            \n",
            "  ...d/checkpoint-step-7000/scheduler.pt: 100%|██████████| 1.47kB / 1.47kB            \n",
            "  ...d/checkpoint-step-7000/optimizer.pt: 100%|██████████|  996MB /  996MB            \n",
            "  ...ckpoint-step-7000/model.safetensors: 100%|██████████|  498MB /  498MB            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Checkpoint-7000 uploaded to polaris314/cadgpt-gpt2-train/checkpoints/checkpoint-step-7000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :   6%|▌         | 92.3MB / 1.49GB,   ???B/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  12%|█▏        |  185MB / 1.49GB,  460MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  18%|█▊        |  268MB / 1.49GB,  440MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  23%|██▎       |  344MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  29%|██▊       |  428MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  35%|███▍      |  520MB / 1.49GB,  427MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  40%|████      |  604MB / 1.49GB,  426MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  46%|████▌     |  688MB / 1.49GB,  425MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  51%|█████     |  763MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  56%|█████▌    |  839MB / 1.49GB,  415MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 6)                :  62%|██████▏   |  931MB / 1.49GB,  419MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  66%|██████▋   |  993MB / 1.49GB,  409MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  69%|██████▊   | 1.03GB / 1.49GB,  389MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  72%|███████▏  | 1.07GB / 1.49GB,  375MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  74%|███████▍  | 1.11GB / 1.49GB,  363MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  77%|███████▋  | 1.15GB / 1.49GB,  353MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  80%|███████▉  | 1.19GB / 1.49GB,  344MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  83%|████████▎ | 1.24GB / 1.49GB,  336MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  86%|████████▌ | 1.28GB / 1.49GB,  329MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  88%|████████▊ | 1.31GB / 1.49GB,  321MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  91%|█████████ | 1.35GB / 1.49GB,  315MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  93%|█████████▎| 1.40GB / 1.49GB,  310MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  96%|█████████▌| 1.43GB / 1.49GB,  304MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 6)                :  99%|█████████▉| 1.48GB / 1.49GB,  302MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  292MB/s  \n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (6 / 6)                : 100%|██████████| 1.49GB / 1.49GB,  269MB/s  \n",
            "New Data Upload                         : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ckpoint-step-3800/training_args.bin: 100%|██████████| 5.78kB / 5.78kB            \n",
            "  .../checkpoint-step-3800/rng_state.pth: 100%|██████████| 14.6kB / 14.6kB            \n",
            "  ...1_st/checkpoint-step-3800/scaler.pt: 100%|██████████| 1.38kB / 1.38kB            \n",
            "  ...t/checkpoint-step-3800/scheduler.pt: 100%|██████████| 1.47kB / 1.47kB            \n",
            "  ...t/checkpoint-step-3800/optimizer.pt: 100%|██████████|  996MB /  996MB            \n",
            "  ...ckpoint-step-3800/model.safetensors: 100%|██████████|  498MB /  498MB            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Checkpoint-3800 uploaded to polaris314/cadgpt-gpt2-train/checkpoints/checkpoint-step-3800\n",
            "\n",
            "🎉 Upload complete!\n",
            "🔗 View your model at: https://huggingface.co/polaris314/cadgpt-gpt2-train\n",
            "📁 Repository structure:\n",
            "  ├── config.json, model.safetensors, etc. (final model)\n",
            "  └── checkpoints/\n",
            "      ├── checkpoint-step-400/\n",
            "      ├── checkpoint-step-600/\n",
            "      └── ...\n"
          ]
        }
      ],
      "source": [
        "# Upload model and checkpoints to single repository with organized structure\n",
        "import shutil\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "def upload_to_single_repo():\n",
        "    \"\"\"Upload final model and important checkpoints to single HF repo\"\"\"\n",
        "    HF_REPO = \"polaris314/cadgpt-gpt2-train\"\n",
        "    print(f\"🎯 Uploading to single repository: {HF_REPO}\")\n",
        "    \n",
        "    api = HfApi(token=HF_TOKEN)\n",
        "    \n",
        "    # Create repository if it doesn't exist\n",
        "    create_repo(HF_REPO, private=True, exist_ok=True, token=HF_TOKEN)\n",
        "    \n",
        "    # 1. Upload final model to root of repo\n",
        "    print(\"🚀 Uploading final model...\")\n",
        "    if os.path.exists(\"/home/ubuntu/cad-llm/cad_llm\"):\n",
        "        api.upload_folder(\n",
        "            folder_path=\"/home/ubuntu/cad-llm/cad_llm\",\n",
        "            repo_id=HF_REPO,\n",
        "            token=HF_TOKEN,\n",
        "            commit_message=\"Upload final trained CAD-LLM model\"\n",
        "        )\n",
        "        print(f\"✅ Final model uploaded to {HF_REPO}\")\n",
        "    else:\n",
        "        print(\"❌ Final model directory not found\")\n",
        "    \n",
        "    # 2. Upload important checkpoints to organized folders\n",
        "    checkpoints_dir = \"/home/ubuntu/cad-llm/notebooks/checkpoints\"\n",
        "    if os.path.exists(checkpoints_dir):\n",
        "        checkpoint_dirs = [d for d in os.listdir(checkpoints_dir) if d.startswith(\"checkpoint-\")]\n",
        "        checkpoint_dirs.sort(key=lambda x: int(x.split(\"-\")[1]))\n",
        "        \n",
        "        print(f\"📦 Found {len(checkpoint_dirs)} total checkpoints...\")\n",
        "        \n",
        "        # Select important checkpoints: last 3 + mid-training\n",
        "        total_checkpoints = len(checkpoint_dirs)\n",
        "        important_checkpoints = []\n",
        "        \n",
        "        if total_checkpoints >= 1:\n",
        "            important_checkpoints.append(checkpoint_dirs[-1])\n",
        "        if total_checkpoints >= 2:\n",
        "            important_checkpoints.append(checkpoint_dirs[-2])\n",
        "        if total_checkpoints >= 3:\n",
        "            important_checkpoints.append(checkpoint_dirs[-3])\n",
        "        if total_checkpoints >= 5:\n",
        "            mid_index = total_checkpoints // 2\n",
        "            important_checkpoints.append(checkpoint_dirs[mid_index])\n",
        "        \n",
        "        print(f\"🎯 Uploading {len(important_checkpoints)} important checkpoints...\")\n",
        "        \n",
        "        # Upload each checkpoint to a subfolder in the same repo\n",
        "        for checkpoint_dir in important_checkpoints:\n",
        "            checkpoint_path = os.path.join(checkpoints_dir, checkpoint_dir)\n",
        "            step_num = checkpoint_dir.split(\"-\")[1]\n",
        "            \n",
        "            # Create temp directory with organized structure\n",
        "            with tempfile.TemporaryDirectory() as temp_dir:\n",
        "                # Copy checkpoint to temp directory with organized name\n",
        "                organized_name = f\"checkpoint-step-{step_num}\"\n",
        "                temp_checkpoint_path = os.path.join(temp_dir, organized_name)\n",
        "                shutil.copytree(checkpoint_path, temp_checkpoint_path)\n",
        "                \n",
        "                try:\n",
        "                    # Upload to subfolder in the same repo\n",
        "                    api.upload_folder(\n",
        "                        folder_path=temp_checkpoint_path,\n",
        "                        repo_id=HF_REPO,\n",
        "                        path_in_repo=f\"checkpoints/{organized_name}\",\n",
        "                        token=HF_TOKEN,\n",
        "                        commit_message=f\"Add checkpoint at step {step_num}\"\n",
        "                    )\n",
        "                    print(f\"✅ Checkpoint-{step_num} uploaded to {HF_REPO}/checkpoints/{organized_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Failed to upload checkpoint-{step_num}: {e}\")\n",
        "    else:\n",
        "        print(\"❌ Checkpoints directory not found\")\n",
        "    \n",
        "    print(\"\\n🎉 Upload complete!\")\n",
        "    print(f\"🔗 View your model at: https://huggingface.co/{HF_REPO}\")\n",
        "    print(\"📁 Repository structure:\")\n",
        "    print(\"  ├── config.json, model.safetensors, etc. (final model)\")\n",
        "    print(\"  └── checkpoints/\")\n",
        "    print(\"      ├── checkpoint-step-400/\")\n",
        "    print(\"      ├── checkpoint-step-600/\")\n",
        "    print(\"      └── ...\")\n",
        "\n",
        "# Run the upload\n",
        "upload_to_single_repo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "test code generation using test_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import cadquery as cq\n",
            "\n",
            "# Parameters from dataset row\n",
            "pressure_bar = 6.2\n",
            "pressure_mpa = 0.62\n",
            "stroke_length = 123\n",
            "cyl_id = 258\n",
            "cyl_len = 160.5\n",
            "cyl_thk = 6\n",
            "cyl_od = 270\n",
            "disc_dia = 257\n",
            "disc_thk = 24.5\n",
            "thru_hole = 20\n",
            "counterbore = 1.75\n",
            "groove_dia = 246\n",
            "groove_height = 7.5\n",
            "head_dia = 34.5\n",
            "head_length = 11\n",
            "neck_dia = 24.5\n",
            "neck_length = 13\n",
            "chamf_dist = 10.1\n",
            "piston_dia = 41\n",
            "piston_length = 172.5\n",
            "ext_length_A = 33\n",
            "ext_dia_A = 20.5\n",
            "threaded_depth = 13.7\n",
            "flange_dia = 275\n",
            "flange_thk = 19\n",
            "hub_od = 255\n",
            "hub_id = 230\n",
            "hub_length = 4\n",
            "ext_dia_B = 258\n",
            "ext_length_B = 4\n",
            "center_hole_dia = 48\n",
            "center_hole_depth = 22\n",
            "bolt_hole_radius = 15.5\n",
            "pattern_radius = 130\n",
            "small_radius = 8\n",
            "n_bolts = 4\n",
            "\n",
            "# flange\n",
            "flange = (cq.Workplane(\"XY\").circle(flange_dia/2).extrude(flange_thk).edges(\">Z\").fillet(1))\n",
            "flange = (flange.faces(\">Z\").workplane(centerOption=\"CenterOfMass\")\n",
            "          .polarArray(pattern_radius, 0, 360, int(n_bolts))\n",
            "          .circle(small_radius).circle(bolt_hole_radius)\n",
            "          .extrude(-flange_thk).edges(\"|Z\").fillet(5))\n",
            "flange = (flange.faces(\">Z\").workplane().hole(center_hole_dia, center_hole_depth))\n",
            "flange_hub = (flange.faces(\">Z\").workplane().center(0,0)\n",
            "              .circle(hub_od/2).circle(hub_id/2).extrude(hub_length))\n",
            "flange = (flange_hub.faces(\">Z\").workplane()\n",
            "          .circle(ext_dia_B/2).circle(hub_id/2).extrude(ext_length\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "MODEL_DIR = \"/home/ubuntu/cad-llm/cad_llm\"  # your saved folder\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_DIR).to(\"cuda\")\n",
        "\n",
        "def generate_code(prompt, max_new_tokens=600, temperature=0.2, top_p=0.95):\n",
        "    prefix = prompt.strip() + \"\\n### CADQUERY CODE\\n\"\n",
        "    inps = tok(prefix, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inps,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "            eos_token_id=tok.eos_token_id,\n",
        "        )\n",
        "    text = tok.decode(out[0], skip_special_tokens=True)\n",
        "    # return only the code after the separator\n",
        "    return text.split(\"### CADQUERY CODE\", 1)[-1].strip()\n",
        "\n",
        "test_prompt = \"Generate a flange for an air motor with cylinder ID 258 mm, stroke length 123 mm, designed for pressure 6.2 bar.\"\n",
        "print(generate_code(test_prompt))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Testing improved code generation...\n",
            "Loading model from /home/ubuntu/cad-llm/cad_llm...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model loaded successfully\n",
            "\n",
            "--- Improved generated code ---\n",
            "import cadquery as cq\n",
            "\n",
            "# Parameters from dataset row\n",
            "pressure_bar = 6.5\n",
            "pressure_mpa = 0.65\n",
            "stroke_length = 120\n",
            "cyl_id = 80\n",
            "cyl_len = 150\n",
            "cyl_thk = 2\n",
            "cyl_od = 84\n",
            "disc_dia = 79.5\n",
            "disc_thk = 14\n",
            "thru_hole = 16\n",
            "counterbore = 3\n",
            "groove_dia = 70\n",
            "groove_height = 7\n",
            "head_dia = 20\n",
            "head_length = 7\n",
            "neck_dia = 10\n",
            "neck_length = 8\n",
            "chamf_dist = 8.4\n",
            "piston_dia = 20\n",
            "piston_length = 168.5\n",
            "ext_length_A = 25\n",
            "ext_dia_A = 16\n",
            "threaded_depth = 22.7\n",
            "flange_dia = 96\n",
            "flange_thk = 14\n",
            "hub_od = 76\n",
            "hub_id = 66\n",
            "hub_length = 4\n",
            "ext_dia_B = 80\n",
            "ext_length_B = 4\n",
            "center_hole_dia = 24\n",
            "center_hole_depth = 9\n",
            "bolt_hole_radius = 3\n",
            "pattern_radius = 48\n",
            "small_radius = 8\n",
            "n_bolts = 3\n",
            "\n",
            "# piston disc\n",
            "cbore_height = 3\n",
            "piston_disc = (cq.Workplane(\"XY\").circle(disc_dia/2).extrude(disc_thk))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane()\n",
            "               .cboreHole(thru_hole, counterbore, cbore_height, depth=None))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -(disc_thk - groove_height)/2)\n",
            "               .circle(groove_dia/2).circle(disc_dia/2).cutBlind(-groove_height))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -groove_height - groove_height)/2)\n",
            "model = piston_disc\n",
            "\n",
            "--- Cleaned code ---\n",
            "import cadquery as cq\n",
            "\n",
            "# Parameters from dataset row\n",
            "pressure_bar = 6.5\n",
            "pressure_mpa = 0.65\n",
            "stroke_length = 120\n",
            "cyl_id =  80\n",
            "cyl_len =  150\n",
            "cyl_thk =  2\n",
            "cyl_od =  84\n",
            "disc_dia = 79.5\n",
            "disc_thk = 14\n",
            "thru_hole = 16\n",
            "counterbore = 3\n",
            "groove_dia = 70\n",
            "groove_height = 7\n",
            "head_dia = 20\n",
            "head_length = 7\n",
            "neck_dia = 10\n",
            "neck_length = 8\n",
            "chamf_dist = 8.4\n",
            "piston_dia = 20\n",
            "piston_length = 168.5\n",
            "ext_length_A = 25\n",
            "ext_dia_A = 16\n",
            "threaded_depth = 22.7\n",
            "flange_dia = 96\n",
            "flange_thk = 14\n",
            "hub_od = 76\n",
            "hub_id = 66\n",
            "hub_length = 4\n",
            "ext_dia_B = 80\n",
            "ext_length_B = 4\n",
            "center_hole_dia = 24\n",
            "center_hole_depth = 9\n",
            "bolt_hole_radius = 3\n",
            "pattern_radius = 48\n",
            "small_radius = 8\n",
            "n_bolts = 3\n",
            "\n",
            "# piston disc\n",
            "cbore_height = 3\n",
            "piston_disc = (cq.Workplane(\"XY\").circle(disc_dia/2).extrude(disc_thk))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane()\n",
            "               .cboreHole(thru_hole, counterbore, cbore_height, depth=None))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -(disc_thk - groove_height)/2)\n",
            "               .circle(groove_dia/2).circle(disc_dia/2).cutBlind(-groove_height))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -groove_height - groove_height)/2)\n",
            "model =  piston_disc\n",
            "\n",
            "✅ SUCCESS! STEP file created: generated_from_llm.step\n"
          ]
        }
      ],
      "source": [
        "# Improved code generation with better completion handling\n",
        "def generate_code_improved(prompt: str, tokenizer, model):\n",
        "    \"\"\"Generate CadQuery code with better completion handling.\"\"\"\n",
        "    prompt_text = prompt.strip() + \"\\n### CADQUERY CODE\\n\"\n",
        "    \n",
        "    try:\n",
        "        inputs = tokenizer(\n",
        "            prompt_text, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=MAX_INPUT_LEN,\n",
        "            padding=True\n",
        "        )\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Tokenization failed: {str(e)}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            gen = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=MAX_NEW_TOKENS,\n",
        "                num_beams=4,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                early_stopping=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Model generation failed: {str(e)}\")\n",
        "\n",
        "    if gen is None or len(gen) == 0:\n",
        "        raise RuntimeError(\"Model returned empty generation\")\n",
        "\n",
        "    try:\n",
        "        # Decode only the new tokens (remove input tokens)\n",
        "        input_length = inputs['input_ids'].shape[1]\n",
        "        output_seq = gen[0][input_length:]\n",
        "        out = tokenizer.decode(output_seq, skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Decoding failed: {str(e)}\")\n",
        "\n",
        "    if not out.strip():\n",
        "        raise RuntimeError(\"Decoded output is empty\")\n",
        "\n",
        "    # Extract code after the separator\n",
        "    if \"### CADQUERY CODE\" in out:\n",
        "        parts = out.split(\"### CADQUERY CODE\", 1)\n",
        "        code = parts[1].strip() if len(parts) > 1 else out\n",
        "    else:\n",
        "        # Look for CadQuery import or model assignment\n",
        "        m = re.search(r\"(import\\s+cadquery\\b.*)\", out, re.S | re.I)\n",
        "        code = m.group(1).strip() if m else out\n",
        "\n",
        "    if not code.strip():\n",
        "        raise RuntimeError(\"No code extracted from generation\")\n",
        "    \n",
        "    # Try to complete incomplete code\n",
        "    code = complete_incomplete_code(code)\n",
        "    \n",
        "    return code\n",
        "\n",
        "def complete_incomplete_code(code: str) -> str:\n",
        "    \"\"\"Try to complete incomplete generated code.\"\"\"\n",
        "    # Remove incomplete lines at the end\n",
        "    lines = code.splitlines()\n",
        "    cleaned_lines = []\n",
        "    \n",
        "    for i, line in enumerate(lines):\n",
        "        # Skip lines that end with incomplete operators\n",
        "        if line.strip().endswith(('.', '(', '=', '+', '-', '*', '/')):\n",
        "            # Check if this is the last line or if next line is empty\n",
        "            if i == len(lines) - 1 or (i < len(lines) - 1 and not lines[i + 1].strip()):\n",
        "                continue\n",
        "        cleaned_lines.append(line)\n",
        "    \n",
        "    code = \"\\n\".join(cleaned_lines)\n",
        "    \n",
        "    # Find the main object variable name\n",
        "    main_object = None\n",
        "    for line in lines:\n",
        "        if re.search(r\"(piston_disc|cylinder|model|part|result)\\s*=\", line):\n",
        "            match = re.search(r\"(\\w+)\\s*=\", line)\n",
        "            if match:\n",
        "                main_object = match.group(1)\n",
        "                break\n",
        "    \n",
        "    # Add final assignment if missing\n",
        "    if main_object and not re.search(r\"\\b(model|result|part)\\s*=\", code):\n",
        "        code += f\"\\nmodel = {main_object}\"\n",
        "    \n",
        "    return code\n",
        "\n",
        "# Test the improved version\n",
        "print(\"🔧 Testing improved code generation...\")\n",
        "prompt = \"generate a piston disc for a pneumatic cylinder of ID 80 mm, stroke length 120 mm, and pressure of 6 bar\"\n",
        "\n",
        "try:\n",
        "    # Load model\n",
        "    tokenizer, model = load_model(MODEL_DIR)\n",
        "    \n",
        "    # Generate code with improved function\n",
        "    raw_code = generate_code_improved(prompt, tokenizer, model)\n",
        "    \n",
        "    print(\"\\n--- Improved generated code ---\")\n",
        "    print(raw_code)\n",
        "    \n",
        "    # Clean and execute\n",
        "    code = clean_generated_code(raw_code)\n",
        "    print(\"\\n--- Cleaned code ---\")\n",
        "    print(code)\n",
        "    \n",
        "    # Sanity check\n",
        "    simple_sanity_check(code)\n",
        "    \n",
        "    # Execute and export\n",
        "    out_file = exec_and_export(code)\n",
        "    print(f\"\\n✅ SUCCESS! STEP file created: {out_file}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Testing with fixed builtins...\n",
            "Loading model from /home/ubuntu/cad-llm/cad_llm...\n",
            "✅ Model loaded successfully\n",
            "\n",
            "--- Code to execute ---\n",
            "import cadquery as cq\n",
            "\n",
            "# Parameters from dataset row\n",
            "pressure_bar = 6.5\n",
            "pressure_mpa = 0.65\n",
            "stroke_length = 120\n",
            "cyl_id =  80\n",
            "cyl_len =  150\n",
            "cyl_thk =  2\n",
            "cyl_od =  84\n",
            "disc_dia = 79.5\n",
            "disc_thk = 14\n",
            "thru_hole = 16\n",
            "counterbore = 3\n",
            "groove_dia = 70\n",
            "groove_height = 7\n",
            "head_dia = 20\n",
            "head_length = 7\n",
            "neck_dia = 10\n",
            "neck_length = 8\n",
            "chamf_dist = 8.4\n",
            "piston_dia = 20\n",
            "piston_length = 168.5\n",
            "ext_length_A = 25\n",
            "ext_dia_A = 16\n",
            "threaded_depth = 22.7\n",
            "flange_dia = 96\n",
            "flange_thk = 14\n",
            "hub_od = 76\n",
            "hub_id = 66\n",
            "hub_length = 4\n",
            "ext_dia_B = 80\n",
            "ext_length_B = 4\n",
            "center_hole_dia = 24\n",
            "center_hole_depth = 9\n",
            "bolt_hole_radius = 3\n",
            "pattern_radius = 48\n",
            "small_radius = 8\n",
            "n_bolts = 3\n",
            "\n",
            "# piston disc\n",
            "cbore_height = 3\n",
            "piston_disc = (cq.Workplane(\"XY\").circle(disc_dia/2).extrude(disc_thk))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane()\n",
            "               .cboreHole(thru_hole, counterbore, cbore_height, depth=None))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -(disc_thk - groove_height)/2)\n",
            "               .circle(groove_dia/2).circle(disc_dia/2).cutBlind(-groove_height))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane(offset = -groove_height - groove_height)/2)\n",
            "model =  piston_disc\n",
            "\n",
            "⚙️ Executing code...\n",
            "✅ CAD object found, exporting...\n",
            "✅ SUCCESS! STEP file created: generated_from_llm.step\n",
            "📁 File size: 18582 bytes\n"
          ]
        }
      ],
      "source": [
        "# Fix the safe builtins issue\n",
        "def get_safe_builtins_fixed():\n",
        "    \"\"\"Return a restricted set of Python builtins (safe for CadQuery).\"\"\"\n",
        "    allowed = {\n",
        "        \"abs\", \"min\", \"max\", \"round\", \"sum\", \"all\", \"any\",\n",
        "        \"int\", \"float\", \"len\", \"range\", \"enumerate\", \"zip\",\n",
        "        \"str\", \"bool\", \"list\", \"tuple\", \"dict\", \"set\",\n",
        "        \"__import__\"  # Add this back for imports to work\n",
        "    }\n",
        "    return {k: getattr(builtins, k) for k in allowed}\n",
        "\n",
        "# Test with fixed builtins\n",
        "print(\"🔧 Testing with fixed builtins...\")\n",
        "\n",
        "try:\n",
        "    # Load model\n",
        "    tokenizer, model = load_model(MODEL_DIR)\n",
        "    \n",
        "    # Generate code\n",
        "    raw_code = generate_code_improved(prompt, tokenizer, model)\n",
        "    \n",
        "    # Clean code\n",
        "    code = clean_generated_code(raw_code)\n",
        "    print(\"\\n--- Code to execute ---\")\n",
        "    print(code)\n",
        "    \n",
        "    # Execute with fixed builtins\n",
        "    safe_globals = {\"cq\": cq, \"__builtins__\": get_safe_builtins_fixed()}\n",
        "    safe_locals = {}\n",
        "    \n",
        "    print(\"\\n⚙️ Executing code...\")\n",
        "    exec(code, safe_globals, safe_locals)\n",
        "    \n",
        "    # Find the CAD object\n",
        "    cad_obj = None\n",
        "    for name in (\"model\", \"result\", \"part\"):\n",
        "        if name in safe_locals:\n",
        "            cad_obj = safe_locals[name]\n",
        "            break\n",
        "        if name in safe_globals:\n",
        "            cad_obj = safe_globals[name]\n",
        "            break\n",
        "    \n",
        "    if cad_obj is None:\n",
        "        print(\"❌ No CAD object found\")\n",
        "    else:\n",
        "        print(\"✅ CAD object found, exporting...\")\n",
        "        out_file = \"generated_from_llm.step\"\n",
        "        cq.exporters.export(cad_obj, out_file)\n",
        "        print(f\"✅ SUCCESS! STEP file created: {out_file}\")\n",
        "        print(f\"📁 File size: {os.path.getsize(out_file)} bytes\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#generate a piston disc for a pneumatic cylinder of ID 80 mm, stroke length 120 mm, and pressure of 6 bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 CAD-LLM Complete Generator Ready!\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 CAD-LLM Code Generator\n",
            "==================================================\n",
            "🤖 Processing prompt: 'generate a piston disc for a pneumatic cylinder of ID 80 mm, stroke length 120 mm, and pressure of 6 bar'\n",
            "Loading model from /home/ubuntu/cad-llm/cad_llm...\n",
            "✅ Model loaded successfully\n",
            "🔄 Generating CadQuery code...\n",
            "\n",
            "--- Raw generated code (first 500 chars) ---\n",
            "import cadquery as cq\n",
            "\n",
            "# Parameters from dataset row\n",
            "pressure_bar = 6.5\n",
            "pressure_mpa = 0.65\n",
            "stroke_length = 120\n",
            "cyl_id = 80\n",
            "cyl_len = 150\n",
            "cyl_thk = 2\n",
            "cyl_od = 84\n",
            "disc_dia = 79.5\n",
            "disc_thk = 14\n",
            "thru_hole = 16\n",
            "counterbore = 3\n",
            "groove_dia = 70\n",
            "groove_height = 7\n",
            "head_dia = 20\n",
            "head_length = 7\n",
            "neck_dia = 10\n",
            "neck_length = 8\n",
            "chamf_dist = 8.4\n",
            "piston_dia = 20\n",
            "piston_length = 168.5\n",
            "ext_length_A = 25\n",
            "ext_dia_A = 16\n",
            "threaded_depth = 22.7\n",
            "flange_dia = 96\n",
            "flange_thk = 14\n",
            "hub_od = 76\n",
            "hub_id = 66\n",
            "hub_length = 4\n",
            "ex...\n",
            "\n",
            "🧹 Cleaning generated code...\n",
            "\n",
            "🔧 Fixing syntax errors...\n",
            "\n",
            "🔧 Completing incomplete code...\n",
            "\n",
            "--- Final cleaned code ---\n",
            "import cadquery as cq\n",
            "\n",
            "# Parameters from dataset row\n",
            "pressure_bar = 6.5\n",
            "pressure_mpa = 0.65\n",
            "stroke_length = 120\n",
            "cyl_id =  80\n",
            "cyl_len =  150\n",
            "cyl_thk =  2\n",
            "cyl_od =  84\n",
            "disc_dia = 79.5\n",
            "disc_thk = 14\n",
            "thru_hole = 16\n",
            "counterbore = 3\n",
            "groove_dia = 70\n",
            "groove_height = 7\n",
            "head_dia = 20\n",
            "head_length = 7\n",
            "neck_dia = 10\n",
            "neck_length = 8\n",
            "chamf_dist = 8.4\n",
            "piston_dia = 20\n",
            "piston_length = 168.5\n",
            "ext_length_A = 25\n",
            "ext_dia_A = 16\n",
            "threaded_depth = 22.7\n",
            "flange_dia = 96\n",
            "flange_thk = 14\n",
            "hub_od = 76\n",
            "hub_id = 66\n",
            "hub_length = 4\n",
            "ext_dia_B = 80\n",
            "ext_length_B = 4\n",
            "center_hole_dia = 24\n",
            "center_hole_depth = 9\n",
            "bolt_hole_radius = 3\n",
            "pattern_radius = 48\n",
            "small_radius = 8\n",
            "n_bolts = 3\n",
            "\n",
            "# piston disc\n",
            "cbore_height = 3\n",
            "piston_disc = (cq.Workplane(\"XY\").circle(disc_dia/2).extrude(disc_thk))\n",
            "piston_disc = (piston_disc.faces(\">Z\").workplane()\n",
            "               .cboreHole(thru_hole, counterbore, cbore_height, depth=None))\n",
            "               .circle(groove_dia/2).circle(disc_dia/2).cutBlind(-groove_height))\n",
            "model = piston_disc\n",
            "\n",
            "🔍 Performing sanity checks...\n",
            "\n",
            "⚙️ Executing code and exporting STEP file...\n",
            "\n",
            "❌ ERROR: Error during code execution: unexpected indent (<string>, line 46)\n",
            "🐛 Debug info saved to last_raw_code.txt\n",
            "❌ Failed: Error during code execution: unexpected indent (<string>, line 46)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_16922/3015484819.py\", line 227, in exec_and_export\n",
            "    exec(code_text, safe_globals, safe_locals)\n",
            "  File \"<string>\", line 46\n",
            "    .circle(groove_dia/2).circle(disc_dia/2).cutBlind(-groove_height))\n",
            "IndentationError: unexpected indent\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_16922/3015484819.py\", line 317, in <module>\n",
            "    out_file, code = generate_cad_from_prompt(prompt)\n",
            "  File \"/tmp/ipykernel_16922/3015484819.py\", line 288, in generate_cad_from_prompt\n",
            "    out_file = exec_and_export(code)\n",
            "  File \"/tmp/ipykernel_16922/3015484819.py\", line 229, in exec_and_export\n",
            "    raise RuntimeError(f\"Error during code execution: {e}\")\n",
            "RuntimeError: Error during code execution: unexpected indent (<string>, line 46)\n"
          ]
        }
      ],
      "source": [
        "# Complete CAD-LLM Code Generator - Single Cell Solution\n",
        "import sys\n",
        "import re\n",
        "import textwrap\n",
        "import os\n",
        "import builtins\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# For headless environments\n",
        "if 'DISPLAY' not in os.environ:\n",
        "    os.environ['DISPLAY'] = ':99'\n",
        "\n",
        "try:\n",
        "    import cadquery as cq\n",
        "except ImportError as e:\n",
        "    print(\"❌ CadQuery import failed. Please install system dependencies:\")\n",
        "    print(\"sudo apt-get install -y libgl1-mesa-glx libgl1-mesa-dev libegl1-mesa\")\n",
        "    print(\"pip install cadquery\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Configuration\n",
        "MODEL_DIR = \"/home/ubuntu/cad-llm/cad_llm\"\n",
        "MAX_NEW_TOKENS = 512\n",
        "MAX_INPUT_LEN = 256\n",
        "\n",
        "def get_safe_builtins():\n",
        "    \"\"\"Return a restricted set of Python builtins (safe for CadQuery).\"\"\"\n",
        "    allowed = {\n",
        "        \"abs\", \"min\", \"max\", \"round\", \"sum\", \"all\", \"any\",\n",
        "        \"int\", \"float\", \"len\", \"range\", \"enumerate\", \"zip\",\n",
        "        \"str\", \"bool\", \"list\", \"tuple\", \"dict\", \"set\",\n",
        "        \"__import__\"\n",
        "    }\n",
        "    return {k: getattr(builtins, k) for k in allowed}\n",
        "\n",
        "def load_model(model_dir=MODEL_DIR):\n",
        "    \"\"\"Load the trained CAD-LLM model and tokenizer.\"\"\"\n",
        "    try:\n",
        "        print(f\"Loading model from {model_dir}...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                model_dir, \n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16\n",
        "            )\n",
        "        else:\n",
        "            model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
        "            model = model.to(\"cpu\")\n",
        "        \n",
        "        model.eval()\n",
        "        print(\"✅ Model loaded successfully\")\n",
        "        return tokenizer, model\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load model from {model_dir}: {e}\")\n",
        "        raise\n",
        "\n",
        "def generate_code(prompt: str, tokenizer, model):\n",
        "    \"\"\"Generate CadQuery code from natural language prompt.\"\"\"\n",
        "    prompt_text = prompt.strip() + \"\\n### CADQUERY CODE\\n\"\n",
        "    \n",
        "    try:\n",
        "        inputs = tokenizer(\n",
        "            prompt_text, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=MAX_INPUT_LEN,\n",
        "            padding=True\n",
        "        )\n",
        "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Tokenization failed: {str(e)}\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        try:\n",
        "            gen = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=MAX_NEW_TOKENS,\n",
        "                num_beams=4,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                repetition_penalty=1.1,\n",
        "                early_stopping=True\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Model generation failed: {str(e)}\")\n",
        "\n",
        "    if gen is None or len(gen) == 0:\n",
        "        raise RuntimeError(\"Model returned empty generation\")\n",
        "\n",
        "    try:\n",
        "        input_length = inputs['input_ids'].shape[1]\n",
        "        output_seq = gen[0][input_length:]\n",
        "        out = tokenizer.decode(output_seq, skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Decoding failed: {str(e)}\")\n",
        "\n",
        "    if not out.strip():\n",
        "        raise RuntimeError(\"Decoded output is empty\")\n",
        "\n",
        "    # Extract code after the separator\n",
        "    if \"### CADQUERY CODE\" in out:\n",
        "        parts = out.split(\"### CADQUERY CODE\", 1)\n",
        "        code = parts[1].strip() if len(parts) > 1 else out\n",
        "    else:\n",
        "        m = re.search(r\"(import\\s+cadquery\\b.*)\", out, re.S | re.I)\n",
        "        code = m.group(1).strip() if m else out\n",
        "\n",
        "    if not code.strip():\n",
        "        raise RuntimeError(\"No code extracted from generation\")\n",
        "    \n",
        "    return code\n",
        "\n",
        "def clean_generated_code(code: str) -> str:\n",
        "    \"\"\"Clean and format the generated CadQuery code.\"\"\"\n",
        "    # Strip markdown fences\n",
        "    code = re.sub(r\"```[a-zA-Z]*\", \"\", code).strip(\"` \\n\")\n",
        "\n",
        "    # Normalize imports\n",
        "    code = re.sub(r\"\\s*(import\\s+cadquery)\", r\"\\n\\1\", code, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Normalize variable assignments\n",
        "    code = re.sub(r\"\\s*(yield_strength|fos|P|cyl_id|cyl_len|cyl_thk|cyl_od|model|result|part)\\s*=\",\n",
        "                  r\"\\n\\1 = \", code)\n",
        "\n",
        "    # Remove excessive trailing parentheses\n",
        "    lines = code.splitlines()\n",
        "    cleaned_lines = []\n",
        "    paren_balance = 0\n",
        "    \n",
        "    for line in lines:\n",
        "        if line.strip() == \")\":\n",
        "            if paren_balance <= 0:\n",
        "                continue\n",
        "        paren_balance += line.count(\"(\") - line.count(\")\")\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "    code = \"\\n\".join(cleaned_lines)\n",
        "\n",
        "    # Balance parentheses if still mismatched\n",
        "    open_parens = code.count('(')\n",
        "    close_parens = code.count(')')\n",
        "    if open_parens > close_parens:\n",
        "        code += '\\n' + (')' * (open_parens - close_parens))\n",
        "\n",
        "    return textwrap.dedent(code).strip()\n",
        "\n",
        "def fix_syntax_errors(code: str) -> str:\n",
        "    \"\"\"Fix common syntax errors in generated code.\"\"\"\n",
        "    lines = code.splitlines()\n",
        "    fixed_lines = []\n",
        "    \n",
        "    for line in lines:\n",
        "        # Fix mismatched parentheses in problematic lines\n",
        "        if \"groove_height - groove_height)/2)\" in line:\n",
        "            continue\n",
        "        elif line.strip().endswith(\"/2)\"):\n",
        "            continue\n",
        "        else:\n",
        "            fixed_lines.append(line)\n",
        "    \n",
        "    return \"\\n\".join(fixed_lines)\n",
        "\n",
        "def complete_incomplete_code(code: str) -> str:\n",
        "    \"\"\"Try to complete incomplete generated code.\"\"\"\n",
        "    lines = code.splitlines()\n",
        "    cleaned_lines = []\n",
        "    \n",
        "    for i, line in enumerate(lines):\n",
        "        if line.strip().endswith(('.', '(', '=', '+', '-', '*', '/')):\n",
        "            if i == len(lines) - 1 or (i < len(lines) - 1 and not lines[i + 1].strip()):\n",
        "                continue\n",
        "        cleaned_lines.append(line)\n",
        "    \n",
        "    code = \"\\n\".join(cleaned_lines)\n",
        "    \n",
        "    # Find the main object variable name\n",
        "    main_object = None\n",
        "    for line in lines:\n",
        "        if re.search(r\"(piston_disc|cylinder|model|part|result)\\s*=\", line):\n",
        "            match = re.search(r\"(\\w+)\\s*=\", line)\n",
        "            if match:\n",
        "                main_object = match.group(1)\n",
        "                break\n",
        "    \n",
        "    # Add final assignment if missing\n",
        "    if main_object and not re.search(r\"\\b(model|result|part)\\s*=\", code):\n",
        "        code += f\"\\nmodel = {main_object}\"\n",
        "    \n",
        "    return code\n",
        "\n",
        "def simple_sanity_check(code_text: str):\n",
        "    \"\"\"Perform basic security and syntax checks on generated code.\"\"\"\n",
        "    forbidden = [\n",
        "        \"__import__\", \"import os\", \"import sys\", \"import subprocess\",\n",
        "        \"open(\", \"eval(\", \"exec(\", \"compile(\",\n",
        "        \"subprocess\", \"socket\", \"requests\", \"urllib\", \n",
        "        \"os.\", \"sys.\", \"globals\", \"locals\", \"__\"\n",
        "    ]\n",
        "    \n",
        "    lower = code_text.lower()\n",
        "    for f in forbidden:\n",
        "        if f in lower:\n",
        "            raise RuntimeError(f\"Forbidden pattern found in generated code: {f}\")\n",
        "\n",
        "    if \"import cadquery\" not in lower:\n",
        "        raise RuntimeError(\"Generated code missing CadQuery import\")\n",
        "    \n",
        "    if not re.search(r\"\\b(model|result|part)\\s*=\", code_text):\n",
        "        raise RuntimeError(\"Generated code missing model/result/part assignment\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "def exec_and_export(code_text: str, out_file=\"generated_from_llm.step\"):\n",
        "    \"\"\"Execute the generated code and export to STEP file.\"\"\"\n",
        "    safe_globals = {\"cq\": cq, \"__builtins__\": get_safe_builtins()}\n",
        "    safe_locals = {}\n",
        "\n",
        "    try:\n",
        "        exec(code_text, safe_globals, safe_locals)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error during code execution: {e}\")\n",
        "\n",
        "    # Find the CAD object\n",
        "    cad_obj = None\n",
        "    for name in (\"model\", \"result\", \"part\"):\n",
        "        if name in safe_locals:\n",
        "            cad_obj = safe_locals[name]\n",
        "            break\n",
        "        if name in safe_globals:\n",
        "            cad_obj = safe_globals[name]\n",
        "            break\n",
        "\n",
        "    if cad_obj is None:\n",
        "        raise RuntimeError(\"No CAD object found. Expected 'model'/'result'/'part' variable.\")\n",
        "\n",
        "    # Export to STEP file\n",
        "    try:\n",
        "        cq.exporters.export(cad_obj, out_file)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to export STEP file: {e}\")\n",
        "    \n",
        "    return out_file\n",
        "\n",
        "def generate_cad_from_prompt(prompt: str):\n",
        "    \"\"\"Main function to generate CAD from natural language prompt.\"\"\"\n",
        "    print(\"🔧 CAD-LLM Code Generator\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if not prompt.strip():\n",
        "        raise ValueError(\"Please provide a valid prompt.\")\n",
        "\n",
        "    print(f\"🤖 Processing prompt: '{prompt}'\")\n",
        "    \n",
        "    # Load model\n",
        "    tokenizer, model = load_model(MODEL_DIR)\n",
        "\n",
        "    try:\n",
        "        print(\"🔄 Generating CadQuery code...\")\n",
        "        raw_code = generate_code(prompt, tokenizer, model)\n",
        "\n",
        "        print(\"\\n--- Raw generated code (first 500 chars) ---\")\n",
        "        print(raw_code[:500] + (\"...\" if len(raw_code) > 500 else \"\"))\n",
        "\n",
        "        print(\"\\n🧹 Cleaning generated code...\")\n",
        "        code = clean_generated_code(raw_code)\n",
        "        \n",
        "        print(\"\\n🔧 Fixing syntax errors...\")\n",
        "        code = fix_syntax_errors(code)\n",
        "        \n",
        "        print(\"\\n🔧 Completing incomplete code...\")\n",
        "        code = complete_incomplete_code(code)\n",
        "        \n",
        "        print(\"\\n--- Final cleaned code ---\")\n",
        "        print(code)\n",
        "\n",
        "        print(\"\\n🔍 Performing sanity checks...\")\n",
        "        simple_sanity_check(code)\n",
        "\n",
        "        print(\"\\n⚙️ Executing code and exporting STEP file...\")\n",
        "        out_file = exec_and_export(code)\n",
        "        print(f\"\\n✅ SUCCESS! STEP file created: {out_file}\")\n",
        "        print(f\"📁 File size: {os.path.getsize(out_file)} bytes\")\n",
        "        \n",
        "        return out_file, code\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERROR: {e}\")\n",
        "        # Save debug info\n",
        "        try:\n",
        "            debug_file = \"last_raw_code.txt\"\n",
        "            with open(debug_file, \"w\") as f:\n",
        "                f.write(raw_code if 'raw_code' in locals() else \"No code generated\")\n",
        "            print(f\"🐛 Debug info saved to {debug_file}\")\n",
        "        except:\n",
        "            pass\n",
        "        raise\n",
        "\n",
        "# ========== MAIN EXECUTION ==========\n",
        "print(\"🚀 CAD-LLM Complete Generator Ready!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Get user input\n",
        "prompt = input(\"Enter your CAD description: \").strip()\n",
        "\n",
        "if not prompt:\n",
        "    print(\"❌ Please provide a valid prompt.\")\n",
        "else:\n",
        "    try:\n",
        "        out_file, code = generate_cad_from_prompt(prompt)\n",
        "        print(f\"\\n🎉 Generated CAD successfully: {out_file}\")\n",
        "        print(f\"📂 File location: {os.path.abspath(out_file)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 CAD-LLM Complete Generator Ready!\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 CAD-LLM Code Generator\n",
            "==================================================\n",
            "🤖 Prompt: 'generate a piston rod for a pneumatic cylinder of ID 120 mm, stroke length 150 mm, and a pressure of 6 bar'\n",
            "Loading model from /home/ubuntu/cad-llm/cad_llm...\n",
            "✅ Model loaded\n",
            "🔄 Generating CadQuery code...\n",
            "\n",
            "❌ ERROR: index out of range in self\n",
            "🐛 Saved raw generation to last_raw_code.txt\n",
            "❌ Failed: index out of range in self\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_16922/3124131107.py\", line 384, in <module>\n",
            "    out_file, code = generate_cad_from_prompt(prompt)\n",
            "  File \"/tmp/ipykernel_16922/3124131107.py\", line 335, in generate_cad_from_prompt\n",
            "    raw = generate_code(prompt, tokenizer, model)\n",
            "  File \"/tmp/ipykernel_16922/3124131107.py\", line 113, in generate_code\n",
            "    out = model.generate(\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 120, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2539, in generate\n",
            "    result = self._sample(\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2870, in _sample\n",
            "    outputs = model_forward(**model_inputs, return_dict=True)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1070, in forward\n",
            "    transformer_outputs = self.transformer(\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 867, in forward\n",
            "    position_embeds = self.wpe(position_ids)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 192, in forward\n",
            "    return F.embedding(\n",
            "  File \"/home/ubuntu/cad-llm/.venv/lib/python3.10/site-packages/torch/nn/functional.py\", line 2546, in embedding\n",
            "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
            "IndexError: index out of range in self\n"
          ]
        }
      ],
      "source": [
        "# Complete CAD-LLM Code Generator - Single Cell Solution (fixed)\n",
        "import sys, re, textwrap, os, builtins, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Headless hint (CadQuery often needs a DISPLAY even if unused)\n",
        "os.environ.setdefault(\"DISPLAY\", \":99\")\n",
        "\n",
        "# --- CadQuery import ---\n",
        "try:\n",
        "    import cadquery as cq\n",
        "except Exception as e:\n",
        "    print(\"❌ CadQuery import failed. You may need system deps and cadquery:\")\n",
        "    print(\"   sudo apt-get install -y libgl1-mesa-glx libgl1-mesa-dev libegl1-mesa\")\n",
        "    print(\"   pip install cadquery\")\n",
        "    raise\n",
        "\n",
        "# --- Config ---\n",
        "MODEL_DIR = os.environ.get(\"CAD_LLM_DIR\", \"/home/ubuntu/cad-llm/cad_llm\")\n",
        "MAX_NEW_TOKENS = 512\n",
        "MAX_INPUT_LEN = 256\n",
        "SEPARATOR = \"\\n### CADQUERY CODE\\n\"\n",
        "\n",
        "# Force the model down the piston-disc route by seeding the code:\n",
        "PISTON_DISC_PREFIX = \"\"\"import cadquery as cq\n",
        "\n",
        "# piston disc\n",
        "\"\"\"\n",
        "\n",
        "# Stop when we see a show_object call (any variable)\n",
        "STOP_REGEX = re.compile(r\"show_object\\s*\\(\")\n",
        "\n",
        "# ---------- Safety ----------\n",
        "def get_safe_builtins():\n",
        "    \"\"\"Restricted Python builtins for exec sandbox.\"\"\"\n",
        "    allowed = {\n",
        "        \"abs\",\"min\",\"max\",\"round\",\"sum\",\"all\",\"any\",\n",
        "        \"int\",\"float\",\"len\",\"range\",\"enumerate\",\"zip\",\n",
        "        \"str\",\"bool\",\"list\",\"tuple\",\"dict\",\"set\",\n",
        "        \"__import__\",  # required for 'import cadquery' to work inside exec\n",
        "    }\n",
        "    return {k: getattr(builtins, k) for k in allowed}\n",
        "\n",
        "FORBIDDEN_SNIPPETS = [\n",
        "    \"import os\", \"import sys\", \"import subprocess\",\n",
        "    \"subprocess\", \"socket\", \"requests\", \"urllib\", \"shutil\",\n",
        "    \"eval(\", \"exec(\", \"compile(\", \"open(\", \"os.\", \"sys.\",\n",
        "    \"__import__(\",  # explicit use in text (Python import still works via builtins)\n",
        "]\n",
        "\n",
        "# ---------- Model load ----------\n",
        "def load_model(model_dir=MODEL_DIR):\n",
        "    print(f\"Loading model from {model_dir}...\")\n",
        "    tok = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_dir, device_map=\"auto\", torch_dtype=torch.float16\n",
        "        )\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_dir).to(\"cpu\")\n",
        "\n",
        "    # 🔑 Ensure embeddings match tokenizer size\n",
        "    model.resize_token_embeddings(len(tok))\n",
        "\n",
        "    model.eval()\n",
        "    print(\"✅ Model loaded\")\n",
        "    return tok, model\n",
        "\n",
        "\n",
        "# ---------- Generation ----------\n",
        "def _strip_to_piston_disc(code: str) -> str:\n",
        "    \"\"\"\n",
        "    If the model rambles into other parts (piston_rod, flange),\n",
        "    keep only the piston disc section.\n",
        "    \"\"\"\n",
        "    # Prefer the region starting at \"# piston disc\" if present\n",
        "    m = re.search(r\"(?ms)^#\\s*piston\\s*disc\\b.*\", code)\n",
        "    if m:\n",
        "        code = m.group(0)\n",
        "\n",
        "    # Hard block: drop any 'piston_rod' or 'flange' blocks that follow\n",
        "    code = re.split(r\"(?ms)^\\s*#\\s*piston\\s*rod\\b|^\\s*#\\s*flange\\b\", code)[0]\n",
        "    return code.strip()\n",
        "\n",
        "\n",
        "def generate_code(prompt: str, tokenizer, model,\n",
        "                  max_rounds=4, max_new_tokens=400, min_new_tokens=120):\n",
        "    \"\"\"\n",
        "    Iteratively generate until we hit 'show_object(' or rounds exhausted.\n",
        "    Trims context to model.config.n_positions (GPT-2 = 1024) each round.\n",
        "    \"\"\"\n",
        "    prefix = prompt.strip() + SEPARATOR\n",
        "    inputs = tokenizer(\n",
        "        prefix, return_tensors=\"pt\",\n",
        "        truncation=True, max_length=MAX_INPUT_LEN, padding=True\n",
        "    )\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    context_ids = inputs[\"input_ids\"]\n",
        "    attn = inputs[\"attention_mask\"]\n",
        "    max_ctx = getattr(model.config, \"n_positions\", 1024)\n",
        "\n",
        "    collected = \"\"\n",
        "    for round_idx in range(max_rounds):\n",
        "        # 🔑 Trim to max context length\n",
        "        if context_ids.shape[1] > max_ctx:\n",
        "            context_ids = context_ids[:, -max_ctx:]\n",
        "            attn = attn[:, -max_ctx:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model.generate(\n",
        "                input_ids=context_ids,\n",
        "                attention_mask=attn,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                min_new_tokens=min_new_tokens,\n",
        "                do_sample=True,\n",
        "                temperature=0.18,\n",
        "                top_p=0.95,\n",
        "                top_k=50,\n",
        "                repetition_penalty=1.05,\n",
        "                num_beams=1,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                use_cache=True,\n",
        "            )\n",
        "\n",
        "        # Take only the newly generated tokens\n",
        "        new_tokens = out[0, context_ids.shape[1]:]\n",
        "        new_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "        collected += new_text\n",
        "\n",
        "        # Update context for next round\n",
        "        context_ids = out\n",
        "        attn = torch.ones_like(context_ids, device=context_ids.device)\n",
        "\n",
        "        # Stop condition\n",
        "        if \"show_object(\" in collected:\n",
        "            break\n",
        "\n",
        "    code = collected.strip()\n",
        "    if not code:\n",
        "        raise RuntimeError(\"No code extracted from generation\")\n",
        "    return code\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Cleaning / Repair ----------\n",
        "def ensure_header(code: str) -> str:\n",
        "    \"\"\"Ensure the code starts with 'import cadquery as cq' or provide cq in scope.\"\"\"\n",
        "    if re.search(r\"\\bimport\\s+cadquery\\b.*\\bas\\b.*\\bcq\\b\", code, re.I):\n",
        "        return code\n",
        "    # If it already has 'import cadquery' without alias, add alias line\n",
        "    if re.search(r\"\\bimport\\s+cadquery\\b\", code, re.I):\n",
        "        return \"import cadquery as cq\\n\" + code\n",
        "    # If no import at all, inject the import so code can run\n",
        "    return \"import cadquery as cq\\n\" + code\n",
        "\n",
        "def clean_generated_code(code: str) -> str:\n",
        "    # strip backtick fences\n",
        "    code = re.sub(r\"```[a-zA-Z]*\", \"\", code).strip(\"`\\n \")\n",
        "\n",
        "    # normalize 'import cadquery' to a clean top line\n",
        "    code = ensure_header(code)\n",
        "\n",
        "    # normalize some assignments with spacing\n",
        "    code = re.sub(\n",
        "        r\"\\s*(yield_strength|fos|P|cyl_id|cyl_len|cyl_thk|cyl_od|model|result|part)\\s*=\",\n",
        "        r\"\\n\\1 = \",\n",
        "        code,\n",
        "    )\n",
        "\n",
        "    # prune lone closing parens at start of lines when unbalanced\n",
        "    lines = code.splitlines()\n",
        "    cleaned, bal = [], 0\n",
        "    for ln in lines:\n",
        "        if ln.strip() == \")\" and bal <= 0:\n",
        "            continue\n",
        "        bal += ln.count(\"(\") - ln.count(\")\")\n",
        "        cleaned.append(ln)\n",
        "    code = \"\\n\".join(cleaned)\n",
        "\n",
        "    # close any remaining opens\n",
        "    opens = code.count(\"(\")\n",
        "    closes = code.count(\")\")\n",
        "    if opens > closes:\n",
        "        code += \"\\n\" + (\")\" * (opens - closes))\n",
        "\n",
        "    return textwrap.dedent(code).strip()\n",
        "\n",
        "def _tidy_method_chains(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Fix common chain formatting issues:\n",
        "    - Remove lines that are only '.' or ',' (stray punctuation).\n",
        "    - If a line is just '.' (or starts with '.'), glue it to previous non-empty line.\n",
        "    - Normalize indentation of chained calls.\n",
        "    \"\"\"\n",
        "    lines = code.splitlines()\n",
        "    out = []\n",
        "    for i, ln in enumerate(lines):\n",
        "        raw = ln.rstrip()\n",
        "\n",
        "        # Drop pure stray punctuation lines\n",
        "        if raw.strip() in {\".\", \",\"}:\n",
        "            continue\n",
        "\n",
        "        # If a line starts with a single dot like \".circle(...)\" but previous line\n",
        "        # does not end with an operator, prepend a safe continuation\n",
        "        if raw.lstrip().startswith(\".\") and out:\n",
        "            prev = out[-1].rstrip()\n",
        "            # If previous already ends with a closing paren, it's fine\n",
        "            # otherwise append a backslash to explicitly continue (legal but optional)\n",
        "            out[-1] = prev  # keep as-is\n",
        "            out.append(raw.lstrip())\n",
        "            continue\n",
        "\n",
        "        out.append(raw)\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "\n",
        "def fix_syntax_errors(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Fix common syntax glitches from the generator:\n",
        "    - Remove known bad fragments.\n",
        "    - Tidy method chains & stray punctuation lines.\n",
        "    - Ensure balanced parentheses (light pass; heavy balance is done in clean_generated_code).\n",
        "    \"\"\"\n",
        "    # Remove specific half-emitted fragments if they appear\n",
        "    bad_fragments = [\n",
        "        \"groove_height - groove_height)/2)\",   # observed garble\n",
        "    ]\n",
        "    for frag in bad_fragments:\n",
        "        code = \"\\n\".join([ln for ln in code.splitlines() if frag not in ln])\n",
        "\n",
        "    # Tidy method chains & drop '.' lines\n",
        "    code = _tidy_method_chains(code)\n",
        "\n",
        "    # If a line ends with just a dot attached to a closing paren, drop the dot\n",
        "    code = re.sub(r\"\\)\\s*\\.\\s*(\\n|$)\", r\")\\n\", code)\n",
        "\n",
        "    # Remove any trailing solitary '.' at EOF\n",
        "    code = re.sub(r\"\\.\\s*$\", \"\", code)\n",
        "\n",
        "    return code\n",
        "\n",
        "\n",
        "def ensure_model_assignment(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Ensure there is a 'model = <shape>' assignment.\n",
        "    If missing, try to use the last assigned variable as model.\n",
        "    \"\"\"\n",
        "    if re.search(r\"\\b(model|result|part)\\s*=\", code):\n",
        "        return code\n",
        "\n",
        "    # Prefer variables that look like CAD objects (appear on the LHS)\n",
        "    candidates = []\n",
        "    for ln in code.splitlines():\n",
        "        m = re.match(r\"\\s*([A-Za-z_][A-Za-z0-9_]*)\\s*=\\s*\", ln)\n",
        "        if m:\n",
        "            candidates.append(m.group(1))\n",
        "\n",
        "    if candidates:\n",
        "        code += f\"\\nmodel = {candidates[-1]}\"\n",
        "    else:\n",
        "        # As a last resort, create an empty workplane so export doesn't crash\n",
        "        code += \"\\nmodel = cq.Workplane('XY')\"\n",
        "    return code\n",
        "\n",
        "    # Heuristic: last variable assigned to a CQ operation\n",
        "    candidates = []\n",
        "    for ln in code.splitlines():\n",
        "        m = re.match(r\"\\s*([A-Za-z_][A-Za-z0-9_]*)\\s*=\\s*\", ln)\n",
        "        if m:\n",
        "            name = m.group(1)\n",
        "            if re.search(rf\"\\b{name}\\s*=\\s*.*cq\\.\", ln):\n",
        "                candidates.append(name)\n",
        "            else:\n",
        "                candidates.append(name)\n",
        "    main = candidates[-1] if candidates else None\n",
        "    if main:\n",
        "        code += f\"\\nmodel = {main}\"\n",
        "    return code\n",
        "\n",
        "# ---------- Checks ----------\n",
        "def simple_sanity_check(code_text: str):\n",
        "    low = code_text.lower()\n",
        "    for token in FORBIDDEN_SNIPPETS:\n",
        "        if token in low:\n",
        "            raise RuntimeError(f\"Forbidden pattern in generated code: {token}\")\n",
        "    # not strictly required if we inject import, but still useful\n",
        "    if \"import cadquery\" not in low:\n",
        "        raise RuntimeError(\"Generated code missing 'import cadquery' import line\")\n",
        "    return True\n",
        "\n",
        "# ---------- Exec & Export ----------\n",
        "def exec_and_export(code_text: str, out_file=\"generated_from_llm.step\"):\n",
        "    safe_globals = {\"cq\": cq, \"__builtins__\": get_safe_builtins()}\n",
        "    safe_locals = {}\n",
        "    try:\n",
        "        exec(code_text, safe_globals, safe_locals)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error during code execution: {e}\")\n",
        "\n",
        "    # Find the CAD object\n",
        "    cad_obj = None\n",
        "    for name in (\"model\", \"result\", \"part\"):\n",
        "        if name in safe_locals:\n",
        "            cad_obj = safe_locals[name]\n",
        "            break\n",
        "        if name in safe_globals:\n",
        "            cad_obj = safe_globals[name]\n",
        "            break\n",
        "    if cad_obj is None:\n",
        "        raise RuntimeError(\"No CAD object found. Expected variable: model/result/part\")\n",
        "\n",
        "    try:\n",
        "        cq.exporters.export(cad_obj, out_file)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to export STEP file: {e}\")\n",
        "    return out_file\n",
        "\n",
        "# ---------- Orchestration ----------\n",
        "def generate_cad_from_prompt(prompt: str):\n",
        "    print(\"🔧 CAD-LLM Code Generator\")\n",
        "    print(\"=\" * 50)\n",
        "    if not prompt.strip():\n",
        "        raise ValueError(\"Please provide a valid prompt.\")\n",
        "\n",
        "    print(f\"🤖 Prompt: {prompt!r}\")\n",
        "    tokenizer, model = load_model(MODEL_DIR)\n",
        "\n",
        "    try:\n",
        "        print(\"🔄 Generating CadQuery code...\")\n",
        "        raw = generate_code(prompt, tokenizer, model)\n",
        "        print(\"\\n--- Raw generation (first 500 chars) ---\")\n",
        "        print(raw[:500] + (\"...\" if len(raw) > 500 else \"\"))\n",
        "\n",
        "        print(\"\\n🧹 Cleaning...\")\n",
        "        code = clean_generated_code(raw)\n",
        "\n",
        "        print(\"🔧 Fixing syntax...\")\n",
        "        code = fix_syntax_errors(code)\n",
        "\n",
        "        print(\"🧩 Ensuring model assignment...\")\n",
        "        code = ensure_model_assignment(code)\n",
        "\n",
        "        print(\"\\n--- Final cleaned code ---\")\n",
        "        print(code)\n",
        "\n",
        "        print(\"\\n🔍 Sanity checks...\")\n",
        "        simple_sanity_check(code)\n",
        "\n",
        "        print(\"⚙️ Executing and exporting STEP...\")\n",
        "        out_file = exec_and_export(code)\n",
        "        print(f\"✅ STEP file created: {out_file}  (size: {os.path.getsize(out_file)} bytes)\")\n",
        "        return out_file, code\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERROR: {e}\")\n",
        "        # Save for debugging\n",
        "        try:\n",
        "            with open(\"last_raw_code.txt\", \"w\") as f:\n",
        "                f.write(raw if 'raw' in locals() else \"[no raw code captured]\")\n",
        "            print(\"🐛 Saved raw generation to last_raw_code.txt\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        raise\n",
        "\n",
        "# ========== MAIN ==========\n",
        "print(\"🚀 CAD-LLM Complete Generator Ready!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    prompt = input(\"Enter your CAD description: \").strip()\n",
        "except EOFError:\n",
        "    # Non-interactive fallback (e.g., piped execution)\n",
        "    prompt = \"\"\n",
        "\n",
        "if not prompt:\n",
        "    print(\"❌ Please provide a valid prompt.\")\n",
        "else:\n",
        "    try:\n",
        "        out_file, code = generate_cad_from_prompt(prompt)\n",
        "        print(f\"\\n🎉 Generated CAD successfully: {out_file}\")\n",
        "        print(f\"📂 File location: {os.path.abspath(out_file)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed: {e}\")\n",
        "        import traceback; traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
